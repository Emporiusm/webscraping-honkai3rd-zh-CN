{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages       = range(100)\n",
    "url_part    = 'https://3rdguide.com/web/valk/detail?id='\n",
    "urls        = [url_part + str(page) for page in pages]\n",
    "souplist    = []\n",
    "df_vstats   = pd.DataFrame()\n",
    "df          = pd.DataFrame()\n",
    "bowls       = len(souplist)\n",
    "vstats      = round(len(df_vstats)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n    Currently there are 100 bowls of soup in the souplist and the 0 sets of stats of in the Dataframe buffer.\n\n    <<list of available functions>>\n\n    loadweb(urls)            - call function to synchronize with the web        - return  souplist:       list\n    savesoup(souplist)       - call function to save the list from loadweb      - output  souplist.pkl    pkl\n    loadsoup(souplist_pkl)   - call function to load local pickle file          - return  souplist:       list\n    soup2stats(souplist)     - call function to parse the souplist              - return  df_vstat:       dataframe\n    savestats(df_vstats)     - call function to save the dataframe              - output  Valkyrie.pkl    pkl\n    loadstats(Valkyrie_pkl)  - call function to load local pickle file          - return  df_vstats:      dataframe\n"
    }
   ],
   "source": [
    "def info():\n",
    "    bowls   = len(souplist)\n",
    "    vstats  = round(len(df_vstats)/5)\n",
    "    print(f\"\"\"\n",
    "    Currently there are {bowls} bowls of soup in the souplist and the {vstats} sets of stats of in the Dataframe buffer.\n",
    "\n",
    "    <<list of available functions>>\n",
    "\n",
    "    loadweb(urls)            - call function to synchronize with the web        - return  souplist:       list\n",
    "    savesoup(souplist)       - call function to save the list from loadweb      - output  souplist.pkl    pkl\n",
    "    loadsoup(souplist_pkl)   - call function to load local pickle file          - return  souplist:       list\n",
    "    soup2stats(souplist)     - call function to parse the souplist              - return  df_vstat:       dataframe\n",
    "    savestats(df_vstats)     - call function to save the dataframe              - output  Valkyrie.pkl    pkl\n",
    "    loadstats(Valkyrie_pkl)  - call function to load local pickle file          - return  df_vstats:      dataframe\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadweb(urls):\n",
    "    htmls       = [urlopen(url).read() for url in urls]\n",
    "    souplist    = [BeautifulSoup(html.decode('utf-8'),'html.parser') for html in htmls]\n",
    "    return souplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadsoup(souplist_pkl):\n",
    "    print('Now loading...')\n",
    "    souplist = pickle.load(souplist_pkl)\n",
    "    return souplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savesoup(souplist):\n",
    "    sys.setrecursionlimit(100000)\n",
    "    print('Now saving...')\n",
    "    with open ('souplist.pkl','wb') as chowder:\n",
    "        pickle.dump(souplist,chowder)\n",
    "        print('Saving completed!')\n",
    "    sys.setrecursionlimit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soup2stats(souplist):\n",
    "    for soup in souplist:\n",
    "        dic = {}\n",
    "        dic.update(enumerate(soup.stripped_strings))\n",
    "        print(dic)\n",
    "        name = dic.get(8)\n",
    "        if not name.startswith('正在'):\n",
    "            header = [\n",
    "                'name',\n",
    "                'rank',\n",
    "                'hp',\n",
    "                'sp',\n",
    "                'atk',\n",
    "                'dfs',\n",
    "                'crt'\n",
    "            ]\n",
    "            b   = [name,'B']    + [dic.get(x) for x in range(14,19)]\n",
    "            a   = [name,'A']    + [dic.get(x) for x in range(19,24)]\n",
    "            s   = [name,'S']    + [dic.get(x) for x in range(24,29)]\n",
    "            ss  = [name,'SS']   + [dic.get(x) for x in range(29,34)]\n",
    "            sss = [name,'SSS']  + [dic.get(x) for x in range(34,39)]\n",
    "            df_vstats  = df.append(pd.DataFrame(data=[b,a,s,ss,sss],columns=header))\n",
    "            df_vstats  = df.reindex()\n",
    "        else:\n",
    "            pass\n",
    "    return df_vstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savestats(df):\n",
    "    print('Now saving...')\n",
    "    df.to_pickle('Valkyrie.pkl')\n",
    "    print('Saving Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadstats(Valkyrie_pkl):\n",
    "    print('Now Loading')\n",
    "    df = pd.read_pickle(Valkyrie_pkl)\n",
    "    return df_vstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "souplist = loadweb(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Now saving...\nSaving completed!\n"
    }
   ],
   "source": [
    "savesoup(souplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{0: '月光社 - 抄作业，就来月光社！', 1: '资讯攻略', 2: '女武神资料', 3: '武器大全', 4: '圣痕资料', 5: '通关队伍推荐', 6: '舰队招募', 7: '登录', 8: '正在加载。。。', 9: '京ICP备18016142号'}\n{0: '月光社 - 抄作业，就来月光社！', 1: '资讯攻略', 2: '女武神资料', 3: '武器大全', 4: '圣痕资料', 5: '通关队伍推荐', 6: '舰队招募', 7: '登录', 8: '御神装·勿忘', 9: 'S8 勿忘', 10: 'Yae Sakura', 11: '7月22日', 12: '杜冥鸦', 13: '佐仓绫音', 14: '--', 15: '--', 16: '--', 17: '--', 18: '--', 19: '--', 20: '--', 21: '--', 22: '--', 23: '--', 24: '1203', 25: '235', 26: '451', 27: '96', 28: '48', 29: '1403', 30: '245', 31: '526', 32: '112', 33: '56', 34: '1604', 35: '256', 36: '604', 37: '128', 38: '64', 39: '扩充补给', 40: '开放世界 战场宝库', 41: '100', 42: '250', 43: '600', 44: '-普通攻击-', 45: '[寒樱斩]', 46: '快速五段斩，每段命中时回复60点动能\\r\\n一段：50%攻击力物理伤害\\r\\n二段：共计80%攻击力物理伤害\\r\\n三段：120%攻击力物理伤害\\r\\n四段：共计120%攻击力物理伤害\\r\\n五段：造成250%攻击力的冰冻元素伤害', 47: '[冻气斩 解锁：S]', 48: '敌人护盾被击破时QTE出场，造成冰冻伤害并冻结敌人', 49: '详细数据', 50: '敌人护盾被击破时QTE出场，发射寒冰剑气，造成600%冰冻元素伤害并冻结敌人4秒', 51: '[六花散乱 解锁：SS]', 52: '普通攻击暴击时回复动能', 53: '详细数据', 54: '普通攻击暴击时回复15.0点动能', 55: '[冰魄 解锁：S]', 56: '普通攻击每击额外造成冰冻伤害，前四段攻击速度提高，使用第五击时伤害提高一段时间', 57: '详细数据', 58: '普通攻击额外造成35%攻击力冰冻元素伤害，前四击期间攻击速度提高30%，使用第五击时，角色获得强化，造成的全伤害提高30%，持续8秒', 59: '-必杀技-', 60: '[寒天狂舞]', 61: '瞬间拔刀斩杀前方敌人\\r\\n烈风：共造成900%攻击力的冰冻元素伤害，最后一击冻结敌人\\r\\n斩杀：冰封粉碎，造成1200%攻击力的物理伤害\\r\\n充能：使用必杀技时回复250点动能，必杀技结束后每0.25秒回复30点动能，持续10秒\\r\\n开启消耗能量：125', 62: '[樱时雨 解锁：SS]', 63: '使用必杀技时额外回复动能', 64: '详细数据', 65: '使用必杀技时额外回复600点动能', 66: '[骨噬 解锁：S]', 67: '必杀技杀死敌人回复自身生命', 68: '详细数据', 69: '必杀技每杀死一个敌人回复自身550点HP', 70: '[无我 解锁：S]', 71: '使用必杀技后造成全伤害提高', 72: '详细数据', 73: '使用必杀技后角色造成的全伤害提高40.0%，持续12秒', 74: '-特殊攻击-', 75: '[零时刃闪]', 76: '高速拔刀斩击\\r\\n消耗200动能可以连续打出强化斩击\\r\\n动能最大值为1000，角色在场时动能会缓慢恢复\\r\\n斩击：50%攻击力物理伤害\\r\\n强化斩击：100%攻击力物理伤害+200%攻击力冰冻元素伤害\\r\\n突进：100%攻击力物理伤害', 77: '[落樱缤纷 解锁：S]', 78: '出场时对周围敌人造成冰冻伤害。出场技和QTE命中时回复动能', 79: '详细数据', 80: '出场时引发寒冰爆炸，对周围敌人造成180%攻击力冰元素伤害。使用出场和QTE时，若命中敌人，则可回复205点动能', 81: '[花之傲骨 解锁：S]', 82: '普攻分支攻击期间受到的全伤害降低，强化斩击额外回复能量', 83: '详细数据', 84: '普通攻击和分支攻击期间抗打断力提高，受到的全伤害降低40.0%，每次使用强化斩击，回复1.5点能量', 85: '[冻牙 解锁：S]', 86: '有动能时分支攻击伤害提高', 87: '详细数据', 88: '强化斩击每击额外造成300%攻击力的冰冻元素伤害', 89: '-闪避-', 90: '[虚影步]', 91: '快速瞬移躲避敌人攻击\\r\\n白影：极限闪避时召唤寒冰残像，残像1秒后爆炸，对周围敌人造成200%攻击力的冰冻元素伤害，冷却时间15秒', 92: '[心意通明 解锁：S]', 93: '残像冷却时间降低', 94: '详细数据', 95: '闪避效果冷却时间降低3.0秒', 96: '[流寒之形 解锁：SSS]', 97: '被残像爆炸波及的敌人概率被冻结', 98: '详细数据', 99: '被残像爆炸波及的敌人有100%概率被冻结4.0秒', 100: '[影息 解锁：S]', 101: '极限闪避时回复动能', 102: '详细数据', 103: '触发极限闪避时立即回复120点动能', 104: '-被动技能-', 105: '[被动技能-勿忘]', 106: '角色自动受被动技能加成', 107: '[仁心 解锁：SS]', 108: '角色在场下也可以回复动能，使用必杀技后快速恢复动能', 109: '详细数据', 110: '角色在场下也可以回复动能，每秒回复10点。使用必杀技后，每0.25秒回复30点动能，持续10秒', 111: '[鬼武 解锁：S]', 112: '攻击眩晕、麻痹、冻结、被时空减速的敌人时伤害提高', 113: '详细数据', 114: '攻击眩晕、麻痹、冻结、被时空减速的敌人时物理和元素伤害提高40.0%', 115: '-队长技-', 116: '[樱之舞]', 117: '置于队长位时，全队受到加成', 118: '[樱之舞]', 119: '全队角色，HP大于80%时，暴击率提高21%，机械属性角色全元素伤害提高36%', 120: '详细数据', 121: '脉冲太刀17式', 122: '斯科特', 123: '斯科特', 124: '斯科特', 125: '[过渡型装备]', 126: '【斯科特】加伤综合，加成高，且限制招式（分支）也为角色的主力输出技（强化斩击），可以说是完美的冰伤过渡圣痕。 武器【脉冲太刀17式】在前期有着较高固伤。且面板较高，契合元素角色。', 127: '仿灵刀·冰昙天', 128: '浓姬', 129: '浓姬', 130: '浓姬', 131: '[老牌冰伤毕业]', 132: '勿忘在加强过后，持续输出能力大幅提升。而在持续输出中，加成稳定且限制较少的【皮里】，相比加成忽高忽低的【浓姬】，要更为优秀。当然，【浓姬】在对群方面的表现依旧强力，全套高加伤，高血量，足以应对复杂的群聚环境。若是将【仿灵刀】超限为【御灵刀】，则更易触发下位的高额元素加成，实力更强。', 133: '御灵刀 寒狱冰天', 134: '薛定谔', 135: '泳装派对', 136: '莎士比亚', 137: '御灵刀 寒狱冰天', 138: '罗伯特·皮里', 139: '罗伯特·皮里', 140: '罗伯特·皮里', 141: '[爆发分支冰伤]', 142: '虽然勿忘现在拥有不错的持续输出能力，但其基础机制：连续分支的爆发依旧强力。搭配上有着高面板、高加伤的超限武器【御灵刀】，配合【薛定谔】上 的瞬间超高全伤，BOSS血条消失不在话下。适用于战场竞速。', 143: '[新·标准毕业]', 144: '全套圣痕加伤综合，且无限制招式，作用于武器主动、分支、必杀技。下位与2件套可以进一步提升勿忘的生存能力（不再依赖大招回血）。现在的勿忘需要普攻第五击提供全伤加成，而3件套的攻速效果，可以优化该方面的手感。 2、3件套的连击增加与连击保持，可有效作用于单件圣痕，不再惧怕频繁断连，而使输出忽高忽低。武器【御灵刀】除了综合加伤外，还能额外回复动能与SP，是当之无愧的毕业武器。', 145: '正在加载。。。', 146: '京ICP备18016142号'}\n"
    },
    {
     "output_type": "error",
     "ename": "UnboundLocalError",
     "evalue": "local variable 'df' referenced before assignment",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-392f49ab5e9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup2stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msouplist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-7463d8f33d3d>\u001b[0m in \u001b[0;36msoup2stats\u001b[0;34m(souplist)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mss\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SS'\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m34\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0msss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SSS'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m34\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m39\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mdf\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mdf\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'df' referenced before assignment"
     ]
    }
   ],
   "source": [
    "df_stats = soup2stats(souplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text        = [content.get_text() for content in soup.findAll('div',class_='valk-details-ji')]\n",
    "title       = [x for x in text[0].split('-') if len(x) < 5]\n",
    "substance   = [x for x in text[0].split(r'-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title[5]:substance[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dic = {}\n",
    "dic.update(enumerate(substance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dic.get(2).replace('''\n",
    "''',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic.get(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic.get(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitwebscrapingconda7e4b416cfac74079af05761bd3c05317",
   "display_name": "Python 3.7.7 64-bit ('web_scraping': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}